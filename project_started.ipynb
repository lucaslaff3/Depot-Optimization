{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports (**Note: install `ipywidgets` and `nodejs` in environment if they are not already**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OM 501<br>\n",
    "Vehicle Routing Project Guidelines<br>\n",
    "DUE DATE: December 4 (wednesday), 2022 @ 6:30pm - 8:30pm.<br>\n",
    "\n",
    "Description:\n",
    "The purpose of this team project is to design, construct, and use a Python application that is capable of solving a capacitated vehicle routing problem with multiple demand points and suggesting a distribution strategy for a subset of U.S. states. For the purpose of this project, a distribution strategy specifies: \n",
    "- how many distribution centers (DCs) to open, \n",
    "- where to open them, \n",
    "- the customer assigned to each DC,\n",
    "- and data insights to support your recommendation.\n",
    "\n",
    "The data you will be using is based on Home Depot locations in the states of California (CA), Texas (TX), and Alabama (AL). You will be determining solutions for each state.\n",
    "Problem assumptions are: \n",
    "- Home Depot distributes goods to \"customer\" stores using a single DC and makes weekly shipments.\n",
    "- Home Depot considers each state separately, i.e., DCs in AL ship only to stores in AL, \n",
    "- Demand is given in pounds. Essentially, we are assuming that the products are \"heavy\", thus, when shipping, we are more constrained by weight rather than volume.\n",
    "- You have access to vehicles that can haul 40,000 in each trip.\n",
    "\n",
    "Presentations:\n",
    "Each team will give a 20 minute presentation detailing their approach to the problem, along with their results for each state and any justification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dateutil\n",
    "import itertools\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "\n",
    "from gurobipy import *\n",
    "from ipywidgets import interact\n",
    "\n",
    "import datetime\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_data(df):\n",
    "\n",
    "    def haversine_np(lon1, lat1, lon2, lat2):\n",
    "        \"\"\"\n",
    "        Calculate the great circle distance between two points\n",
    "        on the earth (specified in decimal degrees)\n",
    "\n",
    "        All args must be of equal length.    \n",
    "\n",
    "        \"\"\"\n",
    "        lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "\n",
    "        a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        miles = 6367 * c * 0.621371\n",
    "        return miles\n",
    "\n",
    "\n",
    "    store_ids = df['store_id'].unique().tolist()\n",
    "    store_ids_product = list(itertools.product(store_ids, store_ids))\n",
    "    dm = pd.DataFrame(store_ids_product, columns=['from', 'to'])\n",
    "    lat_mapper = df.set_index('store_id')['lat'].to_dict()\n",
    "    lon_mapper = df.set_index('store_id')['lon'].to_dict()\n",
    "    dm['from_lat'] = dm['from'].map(lat_mapper)\n",
    "    dm['from_lon'] = dm['from'].map(lon_mapper)\n",
    "    dm['to_lat'] = dm['to'].map(lat_mapper)\n",
    "    dm['to_lon'] = dm['to'].map(lon_mapper)\n",
    "    \n",
    "    lon1, lat1, lon2, lat2 = map(\n",
    "        np.radians, \n",
    "        [dm['from_lon'], \n",
    "        dm['from_lat'], \n",
    "        dm['to_lon'], \n",
    "        dm['to_lat'],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    dm['miles'] = 6367 * c * 0.621371\n",
    "    \n",
    "    dm = dm.pivot(\n",
    "        index='from',\n",
    "        columns='to',\n",
    "        values='miles'\n",
    "    )\n",
    "    \n",
    "    return dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_name</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>zip</th>\n",
       "      <th>store_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manchester-Road</td>\n",
       "      <td>MO</td>\n",
       "      <td>Ballwin</td>\n",
       "      <td>63011</td>\n",
       "      <td>3004</td>\n",
       "      <td>38.6091</td>\n",
       "      <td>-90.5598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellisville</td>\n",
       "      <td>MO</td>\n",
       "      <td>Ellisville</td>\n",
       "      <td>63011</td>\n",
       "      <td>3018</td>\n",
       "      <td>38.6091</td>\n",
       "      <td>-90.5598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>West-Frederick</td>\n",
       "      <td>MD</td>\n",
       "      <td>Frederick</td>\n",
       "      <td>21702</td>\n",
       "      <td>2511</td>\n",
       "      <td>39.4926</td>\n",
       "      <td>-77.4612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-10-Bullard</td>\n",
       "      <td>LA</td>\n",
       "      <td>New-Orleans</td>\n",
       "      <td>70128</td>\n",
       "      <td>352</td>\n",
       "      <td>30.0487</td>\n",
       "      <td>-89.9585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crystal-River</td>\n",
       "      <td>FL</td>\n",
       "      <td>Crystal-River</td>\n",
       "      <td>34429</td>\n",
       "      <td>6332</td>\n",
       "      <td>28.8547</td>\n",
       "      <td>-82.6669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        store_name state           city    zip  store_id      lat      lon\n",
       "0  Manchester-Road    MO        Ballwin  63011      3004  38.6091 -90.5598\n",
       "1       Ellisville    MO     Ellisville  63011      3018  38.6091 -90.5598\n",
       "2   West-Frederick    MD      Frederick  21702      2511  39.4926 -77.4612\n",
       "3     I-10-Bullard    LA    New-Orleans  70128       352  30.0487 -89.9585\n",
       "4    Crystal-River    FL  Crystal-River  34429      6332  28.8547 -82.6669"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = pathlib.Path('data')\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "store_data_filepath = pathlib.Path(data_dir, 'stores.csv')\n",
    "\n",
    "if store_data_filepath.exists():\n",
    "    store_data = pd.read_csv(store_data_filepath)\n",
    "\n",
    "store_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data for a Single State and Demand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 'AL'\n",
    "\n",
    "state_df = store_data[store_data['state']==state]\n",
    "state_df = state_df.reset_index(drop=True)\n",
    "coordinates = state_df.set_index('store_id')[['lat', 'lon']].copy()\n",
    "\n",
    "distance_matrix = get_distance_data(state_df)\n",
    "\n",
    "demand_data_filepath = pathlib.Path(data_dir, 'demand_data.json')\n",
    "with open(demand_data_filepath) as fin:\n",
    "    demand_dict = json.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand Data for Selected State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_stores = state_df['store_id'].tolist()\n",
    "relevant_demand = {key: val for key, val in demand_dict.items() if int(key) in relevant_stores}\n",
    "relevant_demand_df = pd.DataFrame().from_dict(relevant_demand, orient='columns')\n",
    "relevant_demand_df.index = pd.to_datetime(relevant_demand_df.index)\n",
    "relevant_demand_df.columns = [int(val) for val in relevant_demand_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[875,\n",
       " 882,\n",
       " 883,\n",
       " 813,\n",
       " 805,\n",
       " 802,\n",
       " 8577,\n",
       " 806,\n",
       " 801,\n",
       " 817,\n",
       " 816,\n",
       " 888,\n",
       " 6889,\n",
       " 884,\n",
       " 810,\n",
       " 812,\n",
       " 880,\n",
       " 809,\n",
       " 808,\n",
       " 818,\n",
       " 866,\n",
       " 803,\n",
       " 887,\n",
       " 863,\n",
       " 881,\n",
       " 865,\n",
       " 877,\n",
       " 804]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>875</th>\n",
       "      <th>882</th>\n",
       "      <th>883</th>\n",
       "      <th>813</th>\n",
       "      <th>805</th>\n",
       "      <th>802</th>\n",
       "      <th>8577</th>\n",
       "      <th>806</th>\n",
       "      <th>801</th>\n",
       "      <th>817</th>\n",
       "      <th>...</th>\n",
       "      <th>808</th>\n",
       "      <th>818</th>\n",
       "      <th>866</th>\n",
       "      <th>803</th>\n",
       "      <th>887</th>\n",
       "      <th>863</th>\n",
       "      <th>881</th>\n",
       "      <th>865</th>\n",
       "      <th>877</th>\n",
       "      <th>804</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>293</td>\n",
       "      <td>290</td>\n",
       "      <td>318</td>\n",
       "      <td>303</td>\n",
       "      <td>403</td>\n",
       "      <td>468</td>\n",
       "      <td>401</td>\n",
       "      <td>477</td>\n",
       "      <td>486</td>\n",
       "      <td>430</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>278</td>\n",
       "      <td>412</td>\n",
       "      <td>349</td>\n",
       "      <td>396</td>\n",
       "      <td>305</td>\n",
       "      <td>463</td>\n",
       "      <td>483</td>\n",
       "      <td>462</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-12</th>\n",
       "      <td>297</td>\n",
       "      <td>284</td>\n",
       "      <td>317</td>\n",
       "      <td>316</td>\n",
       "      <td>403</td>\n",
       "      <td>468</td>\n",
       "      <td>400</td>\n",
       "      <td>482</td>\n",
       "      <td>483</td>\n",
       "      <td>427</td>\n",
       "      <td>...</td>\n",
       "      <td>510</td>\n",
       "      <td>284</td>\n",
       "      <td>411</td>\n",
       "      <td>345</td>\n",
       "      <td>402</td>\n",
       "      <td>297</td>\n",
       "      <td>477</td>\n",
       "      <td>492</td>\n",
       "      <td>469</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-19</th>\n",
       "      <td>295</td>\n",
       "      <td>286</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>406</td>\n",
       "      <td>461</td>\n",
       "      <td>410</td>\n",
       "      <td>485</td>\n",
       "      <td>485</td>\n",
       "      <td>429</td>\n",
       "      <td>...</td>\n",
       "      <td>506</td>\n",
       "      <td>276</td>\n",
       "      <td>414</td>\n",
       "      <td>352</td>\n",
       "      <td>399</td>\n",
       "      <td>302</td>\n",
       "      <td>476</td>\n",
       "      <td>492</td>\n",
       "      <td>471</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>290</td>\n",
       "      <td>283</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>408</td>\n",
       "      <td>480</td>\n",
       "      <td>410</td>\n",
       "      <td>485</td>\n",
       "      <td>491</td>\n",
       "      <td>421</td>\n",
       "      <td>...</td>\n",
       "      <td>513</td>\n",
       "      <td>278</td>\n",
       "      <td>414</td>\n",
       "      <td>350</td>\n",
       "      <td>397</td>\n",
       "      <td>309</td>\n",
       "      <td>465</td>\n",
       "      <td>496</td>\n",
       "      <td>466</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-02</th>\n",
       "      <td>285</td>\n",
       "      <td>282</td>\n",
       "      <td>312</td>\n",
       "      <td>304</td>\n",
       "      <td>407</td>\n",
       "      <td>467</td>\n",
       "      <td>416</td>\n",
       "      <td>486</td>\n",
       "      <td>488</td>\n",
       "      <td>423</td>\n",
       "      <td>...</td>\n",
       "      <td>501</td>\n",
       "      <td>283</td>\n",
       "      <td>418</td>\n",
       "      <td>350</td>\n",
       "      <td>392</td>\n",
       "      <td>314</td>\n",
       "      <td>470</td>\n",
       "      <td>491</td>\n",
       "      <td>462</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-30</th>\n",
       "      <td>191</td>\n",
       "      <td>138</td>\n",
       "      <td>153</td>\n",
       "      <td>410</td>\n",
       "      <td>547</td>\n",
       "      <td>648</td>\n",
       "      <td>490</td>\n",
       "      <td>311</td>\n",
       "      <td>494</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>475</td>\n",
       "      <td>415</td>\n",
       "      <td>586</td>\n",
       "      <td>398</td>\n",
       "      <td>332</td>\n",
       "      <td>432</td>\n",
       "      <td>390</td>\n",
       "      <td>614</td>\n",
       "      <td>449</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-06</th>\n",
       "      <td>191</td>\n",
       "      <td>136</td>\n",
       "      <td>152</td>\n",
       "      <td>411</td>\n",
       "      <td>543</td>\n",
       "      <td>649</td>\n",
       "      <td>482</td>\n",
       "      <td>315</td>\n",
       "      <td>494</td>\n",
       "      <td>303</td>\n",
       "      <td>...</td>\n",
       "      <td>467</td>\n",
       "      <td>411</td>\n",
       "      <td>588</td>\n",
       "      <td>397</td>\n",
       "      <td>337</td>\n",
       "      <td>435</td>\n",
       "      <td>386</td>\n",
       "      <td>616</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-13</th>\n",
       "      <td>201</td>\n",
       "      <td>139</td>\n",
       "      <td>151</td>\n",
       "      <td>416</td>\n",
       "      <td>546</td>\n",
       "      <td>654</td>\n",
       "      <td>473</td>\n",
       "      <td>307</td>\n",
       "      <td>493</td>\n",
       "      <td>301</td>\n",
       "      <td>...</td>\n",
       "      <td>476</td>\n",
       "      <td>414</td>\n",
       "      <td>588</td>\n",
       "      <td>391</td>\n",
       "      <td>335</td>\n",
       "      <td>420</td>\n",
       "      <td>397</td>\n",
       "      <td>618</td>\n",
       "      <td>454</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-20</th>\n",
       "      <td>193</td>\n",
       "      <td>135</td>\n",
       "      <td>151</td>\n",
       "      <td>410</td>\n",
       "      <td>544</td>\n",
       "      <td>660</td>\n",
       "      <td>488</td>\n",
       "      <td>304</td>\n",
       "      <td>496</td>\n",
       "      <td>290</td>\n",
       "      <td>...</td>\n",
       "      <td>474</td>\n",
       "      <td>408</td>\n",
       "      <td>590</td>\n",
       "      <td>399</td>\n",
       "      <td>331</td>\n",
       "      <td>433</td>\n",
       "      <td>388</td>\n",
       "      <td>620</td>\n",
       "      <td>445</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-27</th>\n",
       "      <td>190</td>\n",
       "      <td>132</td>\n",
       "      <td>147</td>\n",
       "      <td>414</td>\n",
       "      <td>549</td>\n",
       "      <td>652</td>\n",
       "      <td>478</td>\n",
       "      <td>310</td>\n",
       "      <td>495</td>\n",
       "      <td>294</td>\n",
       "      <td>...</td>\n",
       "      <td>472</td>\n",
       "      <td>415</td>\n",
       "      <td>593</td>\n",
       "      <td>399</td>\n",
       "      <td>328</td>\n",
       "      <td>438</td>\n",
       "      <td>383</td>\n",
       "      <td>623</td>\n",
       "      <td>448</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            875  882  883  813  805  802  8577  806  801  817  ...  808  818  \\\n",
       "Date                                                           ...             \n",
       "2020-01-05  293  290  318  303  403  468   401  477  486  430  ...  512  278   \n",
       "2020-01-12  297  284  317  316  403  468   400  482  483  427  ...  510  284   \n",
       "2020-01-19  295  286  314  314  406  461   410  485  485  429  ...  506  276   \n",
       "2020-01-26  290  283  315  307  408  480   410  485  491  421  ...  513  278   \n",
       "2020-02-02  285  282  312  304  407  467   416  486  488  423  ...  501  283   \n",
       "...         ...  ...  ...  ...  ...  ...   ...  ...  ...  ...  ...  ...  ...   \n",
       "2022-01-30  191  138  153  410  547  648   490  311  494  300  ...  475  415   \n",
       "2022-02-06  191  136  152  411  543  649   482  315  494  303  ...  467  411   \n",
       "2022-02-13  201  139  151  416  546  654   473  307  493  301  ...  476  414   \n",
       "2022-02-20  193  135  151  410  544  660   488  304  496  290  ...  474  408   \n",
       "2022-02-27  190  132  147  414  549  652   478  310  495  294  ...  472  415   \n",
       "\n",
       "            866  803  887  863  881  865  877  804  \n",
       "Date                                                \n",
       "2020-01-05  412  349  396  305  463  483  462  265  \n",
       "2020-01-12  411  345  402  297  477  492  469  262  \n",
       "2020-01-19  414  352  399  302  476  492  471  261  \n",
       "2020-01-26  414  350  397  309  465  496  466  259  \n",
       "2020-02-02  418  350  392  314  470  491  462  259  \n",
       "...         ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "2022-01-30  586  398  332  432  390  614  449   66  \n",
       "2022-02-06  588  397  337  435  386  616  457   63  \n",
       "2022-02-13  588  391  335  420  397  618  454   64  \n",
       "2022-02-20  590  399  331  433  388  620  445   61  \n",
       "2022-02-27  593  399  328  438  383  623  448   56  \n",
       "\n",
       "[113 rows x 28 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_data = pd.DataFrame().from_dict(relevant_demand, orient='columns').reset_index()\n",
    "store_data['Date'] = pd.to_datetime(store_data['index'],  format='%Y-%m-%d')\n",
    "store_data = store_data.drop(columns=['index'])\n",
    "store_data = store_data.set_index('Date')\n",
    "store_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "C:\\Users\\rider\\anaconda3\\envs\\opt_env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:536: ValueWarning: No frequency information was provided, so inferred frequency W-SUN will be used.\n",
      "  warnings.warn('No frequency information was'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.426290440752318,\n",
       " 2.1218695682383855,\n",
       " 1.4502247313659657,\n",
       " 5.611441093692198,\n",
       " 2.0868481361848494,\n",
       " 3.9286169215016447,\n",
       " 8.726954546630319,\n",
       " 4.217987460523575,\n",
       " 2.137553733306061,\n",
       " 5.112524678651804,\n",
       " 9.144242894480602,\n",
       " 2.0911880782598726,\n",
       " 4.611528419846311,\n",
       " 13.146373066030645,\n",
       " 1.056294573876079,\n",
       " 5.119726366241629,\n",
       " 2.1254827721084046,\n",
       " 5.881316256262291,\n",
       " 4.886627901288609,\n",
       " 4.944300310609846,\n",
       " 2.257351825952268,\n",
       " 3.263917723055257,\n",
       " 7.105527235481937,\n",
       " 4.201130343855001,\n",
       " 5.873964595330445,\n",
       " 3.1138694234806317,\n",
       " 6.872077468935345,\n",
       " 1.3140176047666157]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_list = []\n",
    "\n",
    "for store in relevant_stores:\n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    train = store_data[str(store)][store_data.index <= pd.to_datetime(\"2021-07-04\", format='%Y-%m-%d')]\n",
    "    test = store_data[str(store)][store_data.index > pd.to_datetime(\"2021-07-04\", format='%Y-%m-%d')]\n",
    "\n",
    "#     plt.plot(train, color = \"black\")\n",
    "#     plt.plot(test, color = \"red\")\n",
    "#     plt.ylabel('Alabama Demand')\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.title(\"Train/Test split for Alabama State Demand\")\n",
    "\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    y = train\n",
    "    test_dates = list(test.index)\n",
    "    test_dates.append(pd.to_datetime(\"2022-06-03\", format='%Y-%m-%d'))\n",
    "\n",
    "    ARIMAmodel = ARIMA(y, order = (2, 2, 2))\n",
    "    ARIMAmodel = ARIMAmodel.fit()\n",
    "\n",
    "    y_pred = ARIMAmodel.get_forecast(len(test.index))\n",
    "    y_pred_df = y_pred.conf_int(alpha = 0.05) \n",
    "    y_pred_df[\"Predictions\"] = ARIMAmodel.predict(start = y_pred_df.index[0], end = y_pred_df.index[-1])\n",
    "    y_pred_df.index = test.index\n",
    "    y_pred_out = y_pred_df[\"Predictions\"] \n",
    "#     plt.plot(y_pred_out, color='Green', label = 'ARIMA Predictions')\n",
    "#     plt.legend()\n",
    "\n",
    "\n",
    "    arma_rmse = np.sqrt(mean_squared_error(test.values, y_pred_df[\"Predictions\"]))\n",
    "    rmse_list.append(arma_rmse)\n",
    "#     print(f'Store number: {store}')\n",
    "#     print(\"RMSE: \", arma_rmse)\n",
    "\n",
    "rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand_prediction(customer_number):\n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "\n",
    "    train = store_data[str(customer_number)][store_data.index <= pd.to_datetime(\"2021-07-04\", format='%Y-%m-%d')]\n",
    "    test = store_data[str(customer_number)][store_data.index > pd.to_datetime(\"2021-07-04\", format='%Y-%m-%d')]\n",
    "\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    y = train\n",
    "    test_dates = list(test.index)\n",
    "    test_dates.append(pd.to_datetime(\"2022-03-06\", format='%Y-%m-%d'))\n",
    "\n",
    "    ARIMAmodel = ARIMA(y, order = (2, 2, 2))\n",
    "    ARIMAmodel = ARIMAmodel.fit()\n",
    "\n",
    "    y_pred = ARIMAmodel.get_forecast(len(test_dates))\n",
    "    y_pred_df = y_pred.conf_int(alpha = 0.05) \n",
    "    y_pred_df[\"Predictions\"] = ARIMAmodel.predict(start = y_pred_df.index[0], end = y_pred_df.index[-1])\n",
    "    y_pred_df.index = test_dates\n",
    "    y_pred_out = y_pred_df[\"Predictions\"] \n",
    "\n",
    "\n",
    "    ## Upper 95% Confidence Demand Predicition \n",
    "    return y_pred_df.loc['2022-03-06'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{875: 199.10191305120193,\n",
       " 882: 134.88837801128835,\n",
       " 883: 150.0967783104618,\n",
       " 813: 435.43403752618383,\n",
       " 805: 553.75756886943,\n",
       " 802: 670.0922036365653,\n",
       " 8577: 514.9288177075169,\n",
       " 806: 312.39378347206343,\n",
       " 801: 496.96678373879513,\n",
       " 817: 304.35048218331804,\n",
       " 816: 624.3757982269314,\n",
       " 888: 127.10404744736721,\n",
       " 6889: 207.00416555878766,\n",
       " 884: 486.90094350777986,\n",
       " 810: 551.078506637042,\n",
       " 812: 329.589922030078,\n",
       " 880: 273.03814791207583,\n",
       " 809: 337.7330836044712,\n",
       " 808: 483.2701040560449,\n",
       " 818: 428.6571353567031,\n",
       " 866: 603.7856284187529,\n",
       " 803: 403.5885373755818,\n",
       " 887: 353.2210666049812,\n",
       " 863: 449.03769346787357,\n",
       " 881: 453.2337468457781,\n",
       " 865: 626.0158715240508,\n",
       " 877: 457.87455214262303,\n",
       " 804: 61.988803406850664}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_demand = {}\n",
    "for store in relevant_stores:\n",
    "    store_demand[store] = demand_prediction(store)\n",
    "\n",
    "store_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = distance_matrix.values.tolist()\n",
    "\n",
    "distance_dict = {}\n",
    "    \n",
    "col_num = 0\n",
    "row_num = 0\n",
    "tot_num = 0\n",
    "for col in distance_matrix.columns:\n",
    "    row_num = 0\n",
    "    for row in distance_matrix:\n",
    "        distance_dict[col, row] = d[col_num][row_num]\n",
    "        row_num += 1\n",
    "    col_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## D IS THS DISTANCE MATRIX FOR ONE POINT TO ANOTHER AS A (Origin, Destination) PAIR IN A DICTIONARY\n",
    "d = distance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_capacity = 40000\n",
    "miles_limit = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best place to put a Depot which would result in the cheapest cost is at Depot #801, costing $61710.01.\n"
     ]
    }
   ],
   "source": [
    "customer_locations = coordinates.index.tolist()\n",
    "\n",
    "depot_cost_dict = {} \n",
    "for test_depot in customer_locations:\n",
    "    customer_locations.remove(test_depot)\n",
    "\n",
    "    pairs = []\n",
    "    for start_customer in customer_locations:\n",
    "        for end_customer in customer_locations:\n",
    "            if start_customer < end_customer:\n",
    "                pairs.append((start_customer, end_customer))\n",
    "\n",
    "    savings = {}\n",
    "    for loc1, loc2 in pairs:\n",
    "        savings[loc1, loc2] = d[test_depot, loc1] + d[test_depot, loc2] - d[loc1, loc2]\n",
    "\n",
    "    savings_df = pd.DataFrame().from_dict(savings, orient='index')\n",
    "    savings_df.columns = ['savings']\n",
    "    savings_df = savings_df.sort_values('savings', ascending=False)\n",
    "    savings = savings_df['savings'].to_dict()\n",
    "\n",
    "    trips = {}\n",
    "    trip_counter = 0\n",
    "    trip_assignments = {customer: -1 for customer in customer_locations}\n",
    "\n",
    "    for loc1, loc2 in savings:\n",
    "\n",
    "        ## IF NEITHER LOCATION IS IN A TRIP\n",
    "        if (trip_assignments[loc1] == -1) and (trip_assignments[loc2] == -1):\n",
    "            capacity_required = store_demand[loc1] + store_demand[loc2]\n",
    "\n",
    "            ## CHECKING THE ORDER TO THE UNCHOSEN POINTS INTO THE TRIP \n",
    "            if d[test_depot, loc1] + d[loc1, loc2] < d[test_depot, loc2] + d[loc2, loc1]:\n",
    "                miles_driven = d[test_depot, loc1] + d[loc1, loc2] + d[loc2, test_depot]\n",
    "                return_trip = d[loc2, test_depot]\n",
    "\n",
    "            else:\n",
    "                miles_driven = d[test_depot, loc2] + d[loc2, loc1] + d[loc1, test_depot]        \n",
    "                return_trip = d[loc1, test_depot]\n",
    "\n",
    "            ##CHECKING IF CAPACITY AND MILEAGE ARE WITHIN CONSTRAINTS \n",
    "            if capacity_required <= vehicle_capacity and miles_driven <= miles_limit:\n",
    "                trip_counter += 1\n",
    "                trips[trip_counter] = {\n",
    "                    'customers': [loc1, loc2],\n",
    "                    'capacity_allocated': capacity_required,\n",
    "                    'miles': miles_driven,\n",
    "                    'return_trip': return_trip\n",
    "                }\n",
    "                ## MAPPING STORES TO TRIP\n",
    "                trip_assignments[loc1] = trip_counter\n",
    "                trip_assignments[loc2] = trip_counter\n",
    "\n",
    "        ## IF FIRST IS IN A TRIP AND SECOND ISN'T\n",
    "        elif (trip_assignments[loc1] >= 0) and (trip_assignments[loc2] == -1):\n",
    "            loc1_trip = trip_assignments[loc1]   ##CHECK LOCAITON ONE'S TRIP NUMBER \n",
    "            loc1_trip_allocation = trips[loc1_trip]['capacity_allocated']     ##LOCATION ONE'S TRIP CAPACITY\n",
    "            loc1_mile_allocation = trips[loc1_trip]['miles']      ##LOCATION  ONE'S TRIP MILEAGE\n",
    "            loc1_return_trip = trips[loc1_trip]['return_trip']     ## LOCATION ONE'S TRIP RETURN TRIP \n",
    "            loc1_end = trips[loc1_trip]['customers'][-1]       ## LOCATION ONE'S LAST CUSTOMER \n",
    "\n",
    "            capacity_required = loc1_trip_allocation + store_demand[loc2]   ## CAPACITY NECESSARY TO ADD LOCATION 2\n",
    "            miles_driven = loc1_mile_allocation + d[loc1_end, loc2] - loc1_return_trip + d[loc2, test_depot]    ## NEW TOTAL MILEAGE DRIVEN\n",
    "\n",
    "            ## IF CONSTRAINTS ARE MET \n",
    "            if capacity_required <= vehicle_capacity and miles_driven <= miles_limit:\n",
    "                trips[loc1_trip]['customers'].append(loc2) ##ADDING TO TRIP\n",
    "                trips[loc1_trip]['capacity_allocated'] = capacity_required  ##UPDATE CAPACITY\n",
    "                trips[loc1_trip]['miles'] = miles_driven   ## UPDATE MILEAGE \n",
    "                trips[loc1_trip]['return_trip'] = d[loc2, test_depot] ## UPDATE RETURN TRIP \n",
    "\n",
    "                trip_assignments[loc2] = loc1_trip ## MAPPING LOCATION 2 TO TRIP \n",
    "\n",
    "        ## IF TRIP 2 IS MAPPED AND TRIP 1 ISNT \n",
    "        elif (trip_assignments[loc2] >= 0) and (trip_assignments[loc1] == -1):\n",
    "            loc2_trip = trip_assignments[loc2] ## CHECK LOCATION 2'S TRIP NUMBER \n",
    "            loc2_trip_allocation = trips[loc2_trip]['capacity_allocated']   ##CHECK CURRENT CAPACITY LOCATION 2 TRIP\n",
    "            loc2_mile_allocation = trips[loc2_trip]['miles']   ## CHECK CURRENT MILEAGE LOCATION 2 TRIP\n",
    "            loc2_return_trip = trips[loc2_trip]['return_trip']  ## CHECK RETURN DISTANCE LOCATION 2 TRIP\n",
    "            loc2_end = trips[loc2_trip]['customers'][-1]    ## LOCATION 2'S TRIP LAST CUSTOMER \n",
    "\n",
    "            capacity_required = loc2_trip_allocation + store_demand[loc1] ## COMPUTING NECESSARY CAPACITY \n",
    "            miles_driven = loc2_mile_allocation + d[loc2_end, loc1] - loc2_return_trip + d[loc1, test_depot] ## COMPUTING NECESSARY MILEAGE \n",
    "\n",
    "            ## IF CONSTRAINTS ARE MET \n",
    "            if capacity_required <= vehicle_capacity and miles_driven <= miles_limit:\n",
    "                trips[loc2_trip]['customers'].append(loc1) ## APPEND TRIP 1\n",
    "                trips[loc2_trip]['capacity_allocated'] = capacity_required ## ASSIGN NEW CAPACITY \n",
    "                trips[loc2_trip]['miles'] = miles_driven ## ASSIGN NEW MILEAGE \n",
    "                trips[loc2_trip]['return_trip'] = d[loc2, test_depot] ## ASSIGN NEW FINAL RETURN TRIP \n",
    "\n",
    "                trip_assignments[loc1] = loc2_trip ## MAP LOCATION 1 TO LOCATION 2 TRIP \n",
    "\n",
    "        ## IF BOTH LOCATIONS ARE IN A TRIP \n",
    "        else:       \n",
    "            loc1_trip = trip_assignments[loc1]   ##CHECK LOCAITON ONE'S TRIP NUMBER \n",
    "            loc1_trip_allocation = trips[loc1_trip]['capacity_allocated']     ##LOCATION ONE'S TRIP CAPACITY\n",
    "            loc1_mile_allocation = trips[loc1_trip]['miles']      ##LOCATION  ONE'S TRIP MILEAGE\n",
    "            loc1_return_trip = trips[loc1_trip]['return_trip']     ## LOCATION ONE'S TRIP RETURN TRIP \n",
    "            loc1_end = trips[loc1_trip]['customers'][-1]       ## LOCATION ONE'S LAST CUSTOMER \n",
    "\n",
    "            loc2_trip = trip_assignments[loc2] ## CHECK LOCATION 2'S TRIP NUMBER \n",
    "            loc2_trip_allocation = trips[loc2_trip]['capacity_allocated']   ##CHECK CURRENT CAPACITY LOCATION 2 TRIP\n",
    "            loc2_mile_allocation = trips[loc2_trip]['miles']   ## CHECK CURRENT MILEAGE LOCATION 2 TRIP\n",
    "            loc2_return_trip = trips[loc2_trip]['return_trip']  ## CHECK RETURN DISTANCE LOCATION 2 TRIP\n",
    "            loc2_end = trips[loc2_trip]['customers'][-1]    ## LOCATION 2'S TRIP LAST CUSTOMER \n",
    "\n",
    "\n",
    "            ## IF THEY ARE NOT IN THE SAME TRIP \n",
    "            if loc1_trip != loc2_trip:\n",
    "                capacity_required = loc1_trip_allocation + loc2_trip_allocation ## CALCULATING NECESSARY CAPACITY \n",
    "                miles_driven = loc1_mile_allocation - loc1_return_trip + d[loc1_end, loc2_end] + loc2_mile_allocation + loc2_return_trip  ## CALCULATING NECESSARY MILEAGE \n",
    "\n",
    "                ## IF CONSTRAINTS ARE MET \n",
    "                if capacity_required <= vehicle_capacity and miles_driven <= miles_limit:\n",
    "                    trips[loc1_trip]['customers'].extend(trips[loc2_trip]['customers']) ## COMBINE THE TWO TRIPS \n",
    "                    trips[loc1_trip]['capacity_allocated'] = capacity_required ## SET THE NEW CAPACITY \n",
    "                    trips[loc1_trip]['miles'] = miles_driven ## SET THE NEW MILES DRIVEN\n",
    "                    trips[loc1_trip]['return_trip'] = loc2_return_trip ## SET THE NEW RETURN TRIP \n",
    "\n",
    "                    ## REMAPPING ALL OF THE NODES IN TRIP TWO TO TRIP ONE  \n",
    "                    for customer in trips[loc2_trip]['customers']:\n",
    "                        trip_assignments[customer] = loc1_trip\n",
    "                    trips.pop(loc2_trip)\n",
    "\n",
    "    ## Parameters for Calculating Total Depot Cost\n",
    "    numCust = 0\n",
    "    numTrucks = 0\n",
    "    numMiles = 0\n",
    "\n",
    "    ## CREATING DATA STRUCTURE FOR OUTPUTTING FULL TRIP DESCRIPTIONS                 \n",
    "    trips = {idx: val for idx, val in enumerate(trips.values(), 1)}\n",
    "\n",
    "    for trip in trips:\n",
    "        numCust += len(trips[trip]['customers'])\n",
    "        trips[trip]['customers'] = [test_depot] + trips[trip]['customers']\n",
    "        numTrucks += 1\n",
    "        numMiles += trips[trip]['miles']\n",
    "\n",
    "    # print(trips)\n",
    "    # print('Number of Trucks:', numTrucks)\n",
    "    # print('Number of Miles: ', numMiles)\n",
    "    # print('Number of Customers: ', numCust)\n",
    "\n",
    "    truck_cost = 2500 * numTrucks + numMiles  \n",
    "    depot_cost = 50000 + numCust*1000\n",
    "    total_cost = truck_cost + depot_cost\n",
    "    depot_cost_dict[test_depot] = total_cost \n",
    "    \n",
    "min_cost = min(depot_cost_dict.values())\n",
    "min_depot = min(depot_cost_dict, key=depot_cost_dict.get)\n",
    "print(f'The best place to put a Depot which would result in the cheapest cost is at Depot #{min_depot}, costing ${round(min_cost, 2)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_CW(cw_trips_dict):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x='lat',\n",
    "        y='lon',\n",
    "        data=coordinates,\n",
    "        edgecolor='k',\n",
    "        alpha=0.5,\n",
    "        s=250,\n",
    "    )\n",
    "    \n",
    "    for trip in cw_trips_dict:\n",
    "        trip_customers = cw_trips_dict[trip]['customers']\n",
    "        tour = solve_tsp_cb(distance_matrix.loc[trip_customers, trip_customers], verbose=False)\n",
    "\n",
    "        for start_index, start_customer in enumerate(tour):\n",
    "            if start_customer == tour[-1]:\n",
    "                next_customer = tour[0]\n",
    "            else:\n",
    "                next_customer = tour[start_index + 1]\n",
    "\n",
    "            xs = [coordinates.loc[start_customer, 'lat'], coordinates.loc[next_customer, 'lat']]\n",
    "            ys = [coordinates.loc[start_customer, 'lon'], coordinates.loc[next_customer, 'lon']]\n",
    "\n",
    "            ax.plot(xs, ys)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_CW(trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_store_demand(selected_store_id):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 5))\n",
    "    \n",
    "    sns.lineplot(\n",
    "        x=relevant_demand_df.index,\n",
    "        y=selected_store_id,\n",
    "        data=relevant_demand_df,\n",
    "    )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "interact(plot_store_demand, selected_store_id=relevant_stores);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSP Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_tsp_cb(dist_df, warmstart=None, verbose=True, time_limit=None):\n",
    "    \"\"\"\n",
    "    This function solves the travelling salesman problem for the problem defined\n",
    "    by a given distance matrix. The function expects the following arguments:\n",
    "    \n",
    "    dist_df: a Pandas DataFrame that specifies the distance between origin-destination (OD) pairs.\n",
    "    All possible values for the origin and desinatiion should be included in the index and\n",
    "    columns of the DataFrame. The value at the intersection of the labels for an OD pair  \n",
    "    is the distance from the origin (row label) to the destination (column label).\n",
    "    \n",
    "    warmstart: a list specifying a tour to use as an initial solution (optional)\n",
    "    \n",
    "    verbose: a flag that can be set to True or False to limit the amount of information\n",
    "    from Gurobi that is written to the screen (optional)\n",
    "    \n",
    "    time_limit: the maximum amount of time that is allowed for Gurobi to attempt to \n",
    "    solve the problem (optional)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Callback - use lazy constraints to eliminate sub-tours\n",
    "    def subtourelim(model, where):\n",
    "        if where == GRB.Callback.MIPSOL:\n",
    "            # make a list of edges selected in the solution\n",
    "            vals = model.cbGetSolution(model._vars)\n",
    "            selected = tuplelist(\n",
    "                (i, j) for i, j in model._vars.keys() if vals[i, j] > 0.5\n",
    "            )\n",
    "            # find the shortest cycle in the selected edge list\n",
    "            tour = subtour(selected)\n",
    "            if len(tour) < n:\n",
    "                tour_sum = LinExpr()\n",
    "                for tour_index, tour_stop in enumerate(tour):\n",
    "                    if tour_index < len(tour) - 1:\n",
    "                        tour_sum += model._vars[tour[tour_index], tour[tour_index + 1]]\n",
    "                    else:\n",
    "                        tour_sum += model._vars[tour[tour_index], tour[0]]\n",
    "                model.cbLazy(tour_sum <= len(tour) - 1)\n",
    "\n",
    "    # Given a list of tuples containing the tour edges, find the shortest subtour\n",
    "    def subtour(edges):\n",
    "        unvisited = list(dist_df.index)\n",
    "        cycle = unvisited + [unvisited[0]]  # initial length has 1 more city\n",
    "        while unvisited:  # true if list is non-empty\n",
    "            thiscycle = []\n",
    "            neighbors = unvisited\n",
    "            while neighbors:\n",
    "                current = neighbors[0]\n",
    "                thiscycle.append(current)\n",
    "                unvisited.remove(current)\n",
    "                neighbors = [j for i, j in edges.select(current, \"*\") if j in unvisited]\n",
    "            if len(cycle) > len(thiscycle):\n",
    "                cycle = thiscycle\n",
    "        return cycle\n",
    "\n",
    "    # Dictionary of Euclidean distance between each pair of points\n",
    "    dist = {\n",
    "        (i, j): dist_df.loc[i, j]\n",
    "        for i in dist_df.index\n",
    "        for j in dist_df.index\n",
    "        if i != j\n",
    "    }\n",
    "\n",
    "    n = len(dist_df.index)\n",
    "\n",
    "    m = Model()\n",
    "    if not verbose:\n",
    "        m.params.OutputFlag = 0\n",
    "    if time_limit:\n",
    "        m.params.TimeLimit = time_limit\n",
    "    # Create variables\n",
    "    trav = m.addVars(dist.keys(), obj=dist, vtype=GRB.BINARY, name=\"e\")\n",
    "\n",
    "    if warmstart:\n",
    "        for warmstart_index, warmstart_stop in enumerate(warmstart):\n",
    "            if warmstart_index < len(warmstart) - 1:\n",
    "                trav[\n",
    "                    warmstart[warmstart_index], warmstart[warmstart_index + 1]\n",
    "                ].Start = 1\n",
    "            else:\n",
    "                trav[warmstart[warmstart_index], warmstart[0]].Start = 1\n",
    "    for i in dist_df.index:\n",
    "        j_sum = LinExpr()\n",
    "        for j in dist_df.index:\n",
    "            if j != i:\n",
    "                j_sum += trav[i, j]\n",
    "        m.addConstr(j_sum == 1)\n",
    "    for j in dist_df.index:\n",
    "        i_sum = LinExpr()\n",
    "        for i in dist_df.index:\n",
    "            if j != i:\n",
    "                i_sum += trav[i, j]\n",
    "        m.addConstr(i_sum == 1)\n",
    "    # Optimize model\n",
    "    m._vars = trav\n",
    "    m.params.Heuristics = 0\n",
    "    m.params.LazyConstraints = 1\n",
    "\n",
    "    m.optimize(subtourelim)\n",
    "\n",
    "    try:\n",
    "        vals = m.getAttr(\"X\", trav)\n",
    "        selected = tuplelist((i, j) for i, j in vals.keys() if vals[i, j] > 0.5)\n",
    "\n",
    "        tour = subtour(selected)\n",
    "        # assert len(tour) == n\n",
    "        \n",
    "        return [int(val) for val in tour]\n",
    "    except:\n",
    "        print(\"No solution found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve TSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tour = solve_tsp_cb(distance_matrix, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x='lon',\n",
    "    y='lat',\n",
    "    data=coordinates,\n",
    "    edgecolor='k',\n",
    "    alpha=0.5,\n",
    "    s=250,\n",
    ")\n",
    "\n",
    "for start_index, start_customer in enumerate(tour):\n",
    "    if start_customer == tour[-1]:\n",
    "        next_customer = tour[0]\n",
    "    else:\n",
    "        next_customer = tour[start_index + 1]\n",
    "        \n",
    "    xs = [coordinates.loc[start_customer, 'lon'], coordinates.loc[next_customer, 'lon']]\n",
    "    ys = [coordinates.loc[start_customer, 'lat'], coordinates.loc[next_customer, 'lat']]\n",
    "    \n",
    "    ax.plot(xs, ys)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
